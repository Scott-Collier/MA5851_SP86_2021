{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c8f182-fa96-4727-a17e-ce117aaa589a",
   "metadata": {},
   "source": [
    "# Web scraper to extract intial specifications and product links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f9991-1ee9-4e24-b8ac-3267ddbb68b5",
   "metadata": {},
   "source": [
    "## DRAFT - currently under development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa8487-f194-4bdd-ba45-235c0183f94c",
   "metadata": {},
   "source": [
    "### Important Details:\n",
    "Website: https://www.appliancesonline.com.au/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f48b8-ac75-4447-8a0c-86d800549c6f",
   "metadata": {},
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a30c86c-3dab-452f-b108-bc2eb3a9edad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "bs4                 4.10.0\n",
       "matplotlib          3.4.3\n",
       "numpy               1.21.2\n",
       "pandas              1.3.4\n",
       "selenium            3.141.0\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         8.4.0\n",
       "anyio                       NA\n",
       "attr                        21.2.0\n",
       "babel                       2.9.1\n",
       "backcall                    0.2.0\n",
       "bottleneck                  1.3.2\n",
       "brotli                      NA\n",
       "certifi                     2021.10.08\n",
       "cffi                        1.14.6\n",
       "chardet                     4.0.0\n",
       "charset_normalizer          2.0.4\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.4.1\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "google                      NA\n",
       "html5lib                    1.1\n",
       "idna                        2.10\n",
       "ipykernel                   6.4.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.17.2\n",
       "jinja2                      2.11.3\n",
       "json5                       NA\n",
       "jsonschema                  3.2.0\n",
       "jupyter_server              1.4.1\n",
       "jupyterlab_server           2.8.2\n",
       "kiwisolver                  1.3.1\n",
       "lxml                        4.6.3\n",
       "markupsafe                  1.1.1\n",
       "matplotlib_inline           NA\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbclassic                   NA\n",
       "nbformat                    5.1.3\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.7.3\n",
       "packaging                   21.0\n",
       "parso                       0.7.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.20\n",
       "pvectorc                    NA\n",
       "pyarrow                     3.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.4.1\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   2.4.7\n",
       "pyrsistent                  NA\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywintypes                  NA\n",
       "requests                    2.26.0\n",
       "send2trash                  NA\n",
       "six                         1.15.0\n",
       "sniffio                     1.2.0\n",
       "socks                       1.7.1\n",
       "soupsieve                   2.2.1\n",
       "sphinxcontrib               NA\n",
       "storemagic                  NA\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.0\n",
       "typing_extensions           NA\n",
       "urllib3                     1.26.7\n",
       "wcwidth                     0.2.5\n",
       "webencodings                0.5.1\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32con                    NA\n",
       "win32security               NA\n",
       "win32trace                  NA\n",
       "winerror                    NA\n",
       "zmq                         22.2.1\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.27.0\n",
       "jupyter_client      7.0.1\n",
       "jupyter_core        4.8.1\n",
       "jupyterlab          3.1.7\n",
       "notebook            6.4.5\n",
       "-----\n",
       "Python 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.19042-SP0\n",
       "-----\n",
       "Session information updated at 2021-12-04 10:15\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import time\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83639b5-a014-4fcc-bdf5-0f1bd1d05870",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0978b6f7-9642-4186-ae7b-29a53635cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(element, element_tag: str, element_type: str):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    To simplify the process of finding and retrieving the value of \n",
    "    an element within an HTML file.\n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    element      :  a selenium.webdriver element\n",
    "    element_tag  :  the tag to search\n",
    "    element_type : 'css_selector', 'container' or 'href' \n",
    "    \n",
    "                    css_selector - retrieves the text of the element\n",
    "                    container - retrieves the selected element\n",
    "                    href - retrieves a link\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    result : the value of the element or the element itself (if it exists),\n",
    "             depending on the element_type selected.\n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    \n",
    "    result = None\n",
    "    try:\n",
    "        if(element_type == 'css_selector'):\n",
    "            result = element.find_element_by_css_selector(element_tag).text\n",
    "        \n",
    "        elif (element_type == 'container'):\n",
    "            result = element.find_element_by_css_selector(element_tag)\n",
    "            \n",
    "        elif (element_type == 'href'):\n",
    "            result = element.find_element_by_class_name(element_tag).get_attribute('href')\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        result = None\n",
    "    except AttributeError:\n",
    "        result = None\n",
    "    \n",
    "    return(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf71d25e-f3d4-4b73-93cc-212c9a31ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_data(driver, data_dict: dict):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    Simplification of data extraction from product pages.\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    driver      : a selenium.webdriver element\n",
    "    data_dict   : the dictionary to store the data\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    User defined function calls:\n",
    "    ---------------------------------------------------------------------\n",
    "    get_element() : to retrieve data from a specific element\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    data_dict : a dictionary that contains the product data from that page\n",
    "    including : ID, Product Name, Product Link, Price, Review Count,\n",
    "    Review Score and Original Price.\n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    Cells = driver.find_elements_by_css_selector('aol-product[trackinglistname=\"grid\"] div.inner')\n",
    "    offset = len(data_dict)\n",
    "    for i, cell in enumerate(Cells):\n",
    "            \n",
    "        # Convert data to a dictionary\n",
    "        data_dict[i+offset] = {\"ID\": str(i+offset).zfill(5),\n",
    "                               \"Product_Name\": get_element(cell, 'div.product-name', 'css_selector'),                                                     \n",
    "                               \"Product_Link\": get_element(cell, 'body-link', 'href'),\n",
    "                               \"Price\": get_element(cell, 'div.price', 'css_selector'),\n",
    "                               \"Review_Count\": get_element(cell, 'span.label', 'css_selector'),\n",
    "                               \"Review_Score\": get_element(cell, 'span.avg-rating', 'css_selector'),\n",
    "                               \"Original_Price\": get_element(cell, 'div.amount', 'css_selector')}\n",
    "\n",
    "    return(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f704d116-ee54-486f-8009-1ce107e581ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openPage(url_prefix: str, url_suffix: str, driver):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    To open a web page of interest and extract data from it.\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    url_prefix  : the prefix of the url to open\n",
    "    url_suffix  : the suffix of the url to open\n",
    "    driver: the selenium web driver used to open the pages\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    User defined function calls:\n",
    "    ---------------------------------------------------------------------\n",
    "    get_product_data() : to retrieve limited product data from a product summary page:\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    product_data : a dictionary that contains the product data from EVERY PAGE\n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    product_data= {}\n",
    "    \n",
    "    # Page to load\n",
    "    page_to_load = url_prefix + '1' + url_suffix\n",
    "    \n",
    "    # Load the web page\n",
    "    driver.get(page_to_load)\n",
    "    sleep(2)\n",
    "    \n",
    "    # Identify the number of products\n",
    "    product_count = int(driver.find_element_by_css_selector('div.products-bar div.products-count').text.split(\" \")[0])\n",
    "    print(f'There were {product_count} products detected')\n",
    "    \n",
    "    #Get data from the first page \n",
    "    product_data = get_product_data(driver, data_dict = product_data)\n",
    "    \n",
    "    # Get data from the rest of the pages\n",
    "    for i in range(2,int((product_count/24)+2)):\n",
    "        sleep(2)\n",
    "        page_to_load = url_prefix + str(i) + url_suffix\n",
    "        driver.get(page_to_load)\n",
    "        sleep(2)\n",
    "        product_data = get_product_data(driver, data_dict = product_data)            \n",
    "    return(product_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbaa6dd0-cf42-431b-9c2c-61621573558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_DataFrame(df: pd.DataFrame, folder: str, filename: str, print_msg: bool = True):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    Save a pandas dataframe to disk using the Pickle file format\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    df        : the dataframe to be saved to disk\n",
    "    folder    : the folder that will hold the file to be saved\n",
    "    filename  : the name of the file to be saved   \n",
    "    print_msg : if True, then print the message that the file has been saved\n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    try:\n",
    "        # Set the path of the file\n",
    "        current_directory = Path(\".\")\n",
    "        filepath = os.path.join(current_directory, folder, filename)\n",
    "        \n",
    "        \n",
    "        with open(filepath, 'wb') as handle:\n",
    "            pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        if print_msg:\n",
    "            print('')\n",
    "            print(f'Dataframe has been saved to : //{folder}/{filename}')\n",
    "        \n",
    "    except:\n",
    "        print(f'Problem saving the file: {filename} - Try again.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e212d9-6447-489a-8af4-aa98046f1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_DataFrame : helper function     \n",
    "def load_DataFrame(folder: str, filename: str, print_msg: bool = True):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    Load a pandas dataframe from disk that was previously saved\n",
    "    using the Pickle file format\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    folder    : the name of the folder to search for file (string)\n",
    "    filename  : the name of the file to load  (string)\n",
    "    print_msg : if True, then print the message that the file has been saved\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    df : the pandas dataframe that was previously saved to disk\n",
    "    \n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    df = None\n",
    "    \n",
    "    try:\n",
    "        # Set the filepath\n",
    "        current_directory = Path(\".\")\n",
    "        filepath = os.path.join(current_directory, folder, filename)\n",
    "        \n",
    "        with open(filepath, 'rb') as handle:\n",
    "            df = pickle.load(handle)\n",
    "        \n",
    "        if print_msg:\n",
    "            print(f'Loaded: {filename}')\n",
    "        \n",
    "    except:\n",
    "        print(f'Problem loading :{filename} : \\n {filepath}')\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a2c073-f0ba-4420-8a19-6d3059ef2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    Checks if the 'num' value is NaN\n",
    "    ---------------------------------------------------------------------\n",
    "  \n",
    "  \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    num : the value to be checked\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    True : if num is NaN\n",
    "    False: if num is not NaN\n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    \n",
    "    return num != num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26e3996-1707-455f-801b-12fded3c2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Duration(start: float, stop: float, msg: str = 'Duration:'):\n",
    "    '''\n",
    "    Functionality:\n",
    "    ---------------------------------------------------------------------\n",
    "    Prints the time difference between start and stop times\n",
    "    ---------------------------------------------------------------------\n",
    "  \n",
    "  \n",
    "    Parameters:\n",
    "    ---------------------------------------------------------------------\n",
    "    start : a float representing when the timer was started\n",
    "    stop  : a float representing when the timer was stopped\n",
    "    msg   : a message to display before the time difference. eg.(Duration:)\n",
    "    ---------------------------------------------------------------------\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------------------------------\n",
    "    A string containing the message, and the duration in minutes and seconds\n",
    "    ---------------------------------------------------------------------\n",
    "    '''\n",
    "    \n",
    "    mins = str(int((stop - start) / 60)).zfill(2)\n",
    "    secs = str(int((stop - start) % 60)).zfill(2)\n",
    "    \n",
    "    return(f'{msg}{mins}:{secs}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcd38b-a195-46bc-b8a9-5e210b0cfafd",
   "metadata": {},
   "source": [
    "# RETRIEVE INITIAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24c0f7ec-c8bd-4765-a871-f4f6b1a8f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 147 products detected\n",
      "Time taken to download data: 00:51\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "SAVE FILENAME: Please enter the name of the file: TV_names_and_links_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe has been saved to : //Product/TV_names_and_links_df.pkl\n"
     ]
    }
   ],
   "source": [
    "# Product page that lists the products\n",
    "page_prefix = 'https://www.appliancesonline.com.au/filter/consumer-electronics/tvs/?currentpage='\n",
    "page_suffix = '&sortkey=highestrated'  \n",
    "\n",
    "# incognito mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')\n",
    "driverPATH = 'C:\\\\University\\\\Master Class\\\\chromedriver_win32\\\\chromedriver.exe'\n",
    "chrome_Browser = webdriver.Chrome(driverPATH, options=chrome_options)\n",
    "\n",
    "# Start the timer\n",
    "start_timer = time.perf_counter() \n",
    "\n",
    "# Get the product names and links and convert to a dataframe\n",
    "product_dict = openPage(page_prefix, page_suffix, chrome_Browser)\n",
    "product_df = pd.DataFrame(product_dict).T\n",
    "\n",
    "# Stop the timer and display the time taken to download the data\n",
    "stop_timer = time.perf_counter()\n",
    "print(get_Duration(start_timer, stop_timer, 'Time taken to download data: '))\n",
    "\n",
    "#Close the browser\n",
    "chrome_Browser.quit()\n",
    "\n",
    "# Save the product_df to disk in the 'Product' Folder\n",
    "filename = input(\"SAVE FILENAME: Please enter the name of the file:\")\n",
    "save_DataFrame(df = product_df, folder='Product', filename=f'{filename}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de774bac-4b88-4a8c-8172-4d5bd9a5a710",
   "metadata": {},
   "source": [
    "# RETRIEVE DETAILED DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7cf4654b-a543-4b1c-a6eb-5dad08cdd571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: TV_names_and_links_df.pkl\n",
      "..........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140......\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Group_total</th>\n",
       "      <th>Scrape_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>1320</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>1320</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>314</td>\n",
       "      <td>1320</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>374</td>\n",
       "      <td>1320</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>550</td>\n",
       "      <td>1126</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Round Reviews Group_total Scrape_time\n",
       "0       0     298        1320       00:44\n",
       "1       1     326        1320       00:44\n",
       "2       2     314        1320       00:45\n",
       "3       3     374        1320       00:45\n",
       "4       4     550        1126       00:38\n",
       "..    ...     ...         ...         ...\n",
       "142   142       0           1       00:15\n",
       "143   143       0           1       00:15\n",
       "144   144       0           1       00:15\n",
       "145   145       0           1       00:15\n",
       "146   146       0           1       00:15\n",
       "\n",
       "[147 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the previously saved product dataframe that contains the links required\n",
    "product_df = load_DataFrame('Product', f'{filename}.pkl')\n",
    "\n",
    "# Identify the number of products\n",
    "n = len(product_df['Product_Link'])\n",
    "\n",
    "# Dictionary to hold the download statistics\n",
    "download_stats = {}\n",
    "\n",
    "#Retrieve the data from every product web page -------------------------------------------------------------------------------------\n",
    "for i in range(0, n):\n",
    "    \n",
    "    # Start timer for this round\n",
    "    start_timer = time.perf_counter() \n",
    "    \n",
    "    # SETUP -----------------------------------------------------------------------------\n",
    "    \n",
    "    # incognito mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--incognito')\n",
    "    driverPATH = 'C:\\\\University\\\\Master Class\\\\chromedriver_win32\\\\chromedriver.exe'\n",
    "    chrome_Browser = webdriver.Chrome(driverPATH, options=chrome_options)\n",
    "    \n",
    "    # Setup the variables to hold the data\n",
    "    Overview = {}\n",
    "    Specifications = {}\n",
    "    Review_cage = []\n",
    "    Reviews = {}\n",
    "    page_to_load = product_df['Product_Link'][i]\n",
    "\n",
    "    # Load the page and then maximise the window (must be maximised - limitation)\n",
    "    chrome_Browser.get(page_to_load)\n",
    "    sleep(2)\n",
    "    chrome_Browser.maximize_window()\n",
    "    sleep(5)\n",
    "    \n",
    "    page_source = chrome_Browser.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # OVERVIEW DATA  ----------------------------------------------------------------------\n",
    "    if soup.find('div', class_='product-description') is not None:\n",
    "        overview = soup.find('div', class_='product-description').text\n",
    "    else:\n",
    "        overview = None\n",
    "   \n",
    "    Overview[i] = {'ID': str(i).zfill(5),\n",
    "                   'Overview' : overview}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # DETAILED PRODUCT SPECIFICATIONS  --------------------------------------------------\n",
    "    detailed_specs = {}\n",
    "    detailed_specs['ID'] = str(i).zfill(5)\n",
    "       \n",
    "    for j in [1,2]:\n",
    "        for k in range(1, 8):\n",
    "            \n",
    "            # Panel path split for readability\n",
    "            panel_path = [f'#page-container > aol-product-page-container > aol-product-page > ul > li.grey.full.ng-star-inserted ',\n",
    "                          f'> aol-product-page-content-middle > aol-product-navigation > div > aol-product-page-section:nth-child(4) ',\n",
    "                          f'> section > div.section-content > aol-product-specifications > div > div:nth-child({j}) ', \n",
    "                          f'> aol-specifications-panel:nth-child({k}) > div > aol-product-specifications-attribute-row']\n",
    "    \n",
    "            p_path = panel_path[0] + panel_path[1] + panel_path[2] + panel_path[3]\n",
    "            \n",
    "            # Get all the rows in the panel\n",
    "            rows = soup.select(p_path)\n",
    "            \n",
    "            # Skipping specific UNWANTED panels\n",
    "            skip = False\n",
    "            if (j<2 and k>6):\n",
    "                skip = True\n",
    "            \n",
    "            # Extract the label and value for each row in the panel\n",
    "            if not skip:\n",
    "                for row in rows:\n",
    "                    # EVERY row will have a label - no need to check\n",
    "                    label = row.find('span', class_='attribute-name-text').text\n",
    "                    \n",
    "                    # There are three possible values, 1. normal text, 2.brand (link), 3. tick (svg image)\n",
    "                    if row.find('div', class_= 'attribute-value') is not None:\n",
    "                        value = row.find('div', class_= 'attribute-value').text\n",
    "                    elif row.find('a', class_= 'attribute-value') is not None:\n",
    "                        value = row.find('a', class_= 'attribute-value').text\n",
    "                    else:\n",
    "                        value = 'tick'\n",
    "\n",
    "                    detailed_specs[label] = value\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # REVIEWS ----------------------------------------------------------------------------------\n",
    "    # Get the number of reviews\n",
    "    if isNaN(product_df['Review_Count'][i]):\n",
    "        Review_count = 0\n",
    "    elif product_df['Review_Count'][i] is None:\n",
    "        Review_count = 0\n",
    "    else:\n",
    "        Review_count = int((product_df['Review_Count'][i]).split(\" \")[1])\n",
    "        \n",
    "    stars = []\n",
    "    if Review_count > 0:\n",
    "        for j in range(2, 7):\n",
    "            link = ['#page-container > aol-product-page-container > aol-product-page > ul > li.grey.full.ng-star-inserted ', \n",
    "                    '> aol-product-page-content-middle > aol-product-navigation > div > aol-product-page-section:nth-child(5) ',\n",
    "                    '> section > div.section-content > aol-product-reviews > div > aol-reviews-summary > div ',\n",
    "                    f'> div.summary.review.ng-star-inserted > div:nth-child({j}) > div.rating-number']\n",
    "            star_link = link[0]+link[1]+link[2]+link[3]\n",
    "            stars.append(soup.select(star_link)[0].text)\n",
    "            \n",
    "        counter = 1\n",
    "        for star_count in stars[::-1]:\n",
    "            detailed_specs[f'{counter}_star'] = int(star_count.replace(',',''))\n",
    "            counter += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save the detailed specifications into the Specifications dictionary\n",
    "    Specifications[i] = detailed_specs\n",
    "    \n",
    "\n",
    "\n",
    "    # Check if the 'show more' button exists (needs more than 5 reviews)\n",
    "    if get_element(chrome_Browser, 'wui-button.ng-star-inserted button.primary', 'container') is not None:\n",
    "        show_more = get_element(chrome_Browser, 'wui-button.ng-star-inserted button.primary', 'container') \n",
    "    \n",
    "        # Display the HIDDEN reviews by clicking the 'show more' button as many times as necessary\n",
    "        for j in range(1,Review_count,5):\n",
    "            \n",
    "            # Javascript button needs a special method to work properly\n",
    "            # As recommended by : https://stackoverflow.com/questions/48665001/can-not-click-on-a-element-elementclickinterceptedexception-in-splinter-selen\n",
    "                \n",
    "            try:\n",
    "                chrome_Browser.execute_script(\"arguments[0].click();\", show_more)     \n",
    "            except StaleElementReferenceException:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    # A dictionary to store the reviews\n",
    "    review_dict = {}\n",
    "    \n",
    "    # Set the new page source\n",
    "    page_source = chrome_Browser.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    \n",
    "    # Check if the review panel exists\n",
    "    if soup.select('aol-reviews-item.review') is not None:\n",
    "        Review_panel = soup.select('aol-reviews-item.review')\n",
    "        \n",
    "        # START the Review timer\n",
    "        rev_tic = time.perf_counter() \n",
    "        \n",
    "        # Extract all the Reviews\n",
    "        for j, review in enumerate(Review_panel):\n",
    "\n",
    "            # Check for disclaimers\n",
    "            disclaimer = review.find('div', class_='syndication')\n",
    "            \n",
    "            # If a disclaimer exists, then retrieve the message of where it was originally posted, \n",
    "            # and what size screen the post is about\n",
    "            if disclaimer is not None:\n",
    "                try:\n",
    "                    orig_posted = disclaimer.find('span', class_= 'syndication-text').text\n",
    "                except:\n",
    "                    orig_posted = None\n",
    "                \n",
    "                try:\n",
    "                    disclaimer_size = disclaimer.find('span', class_= 'syndication-text-label').text\n",
    "                except:\n",
    "                    disclaimer_size = None\n",
    "                \n",
    "            # Count the stars\n",
    "            star_list = review.select('svg-icon.full-star.ng-star-inserted')\n",
    "            star_count = len(star_list)\n",
    "\n",
    "            # Do not include reviews for products that have a size disclaimer\n",
    "            if disclaimer_size is None:\n",
    "                review_dict[j] = {'ID': str(i).zfill(5),\n",
    "                                  'Review_num' : str(j).zfill(5),\n",
    "                                  'Review_star_count' : star_count,\n",
    "                                  'Review_customer_name' : review.find('span', class_='name').text,\n",
    "                                  'Review_date' : review.find('span', class_='date').text,\n",
    "                                  'Review_title': review.find('div', class_='title').text,\n",
    "                                  'Review_text': review.find('div', class_='text').text,\n",
    "                                  'Review_originally_posted': orig_posted,\n",
    "                                  'Review_disclaimer_size': disclaimer_size }\n",
    "\n",
    "    # Save ALL of the product reviews (in review_dict) to 'Reviews'\n",
    "    Reviews[i] = review_dict  \n",
    "    \n",
    "    \n",
    "    # CLEAN UP ------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "    # Close the browser\n",
    "    chrome_Browser.quit()\n",
    "    \n",
    "    \n",
    "    # Put data into dataframes and Save to disk\n",
    "    Overview_df = pd.DataFrame(Overview[i],[i])\n",
    "    Specifications_df = pd.DataFrame(Specifications[i],[i])\n",
    "    Key_specs_df = pd.merge(Overview_df, Specifications_df, on='ID')\n",
    "    Reviews_df = pd.DataFrame(Reviews[i]).T\n",
    "    save_DataFrame(Reviews_df, 'Reviews', f'Reviews_{i}.pkl', print_msg=False)\n",
    "    save_DataFrame(Key_specs_df, 'Key_specs', f'KeySpecs_{i}.pkl', print_msg=False)\n",
    "    \n",
    "    # Stop the timer for this round\n",
    "    stop_timer = time.perf_counter() \n",
    "    download_stats[i] = {'Round': i,\n",
    "                         'Reviews': len(review_dict),\n",
    "                         'Group_total': Review_count,\n",
    "                         'Scrape_time': get_Duration(start_timer, stop_timer, '') }\n",
    "    \n",
    "    \n",
    "    # Show download progress\n",
    "    if i%10 == 0:\n",
    "        if i == 0 :\n",
    "            print('.', end='')\n",
    "        else:\n",
    "            print(i, end='')\n",
    "    else:\n",
    "        print('.', end='')\n",
    "\n",
    "        \n",
    "# Show the downlaod stats \n",
    "print('\\n\\n')\n",
    "download_stats_df = pd.DataFrame(download_stats).T  \n",
    "download_stats_df = download_stats_df[['Round', 'Reviews', 'Group_total', 'Scrape_time']]\n",
    "display(download_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f46a61a5-fe44-4bbc-b844-f5f99c4cea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaOUlEQVR4nO3de9ylZV3v8c8XBuSkAjHQCOiAEqZuDzieMs1Ed3iE9pYdljUZSm3NNG3naOahHYllKm23B1JjUkMQDxDtUhoFNE0cBLccpAFBZpqJGQ8EJIngrz/u67lZPj3PzOJh1lrP4fN+vdZr3ad1r9+1npn7u67rXuteqSokSQLYZdIFSJLmD0NBktQzFCRJPUNBktQzFCRJPUNBktQzFJaoJFckecqk61isfH3nJslTkmyadB1LmaGwCCW5PsnTpi371SSfn5qvqodW1QU72M/KJJVk2YhKnaiB9t3abtcnWbMz9j3M66vRSXJBkhdNuo6FaFH+Z9fCkGRZVd0x6TqAfavqjiSrgAuTXFJV50+6qEnbGX+fefQ31pDsKSxRg72JJI9Nsj7JzUluTPK2ttlF7f6m9k76CUl2SfK6JN9MsjXJXya578B+f6Wt+3aS35/2PG9McnaSDyW5GfjV9txfTHJTki1J3plk94H9VZKXJNmQ5JYk/zvJA9tjbk5y1uD290RVrQeuAB458Py/luSqJN9N8qkkD2jL35PkrdNe03OSvHKG13eXJGuSXNtel7OS7N/WrU3yqjZ98FR72/yDknwnnQOSnNdep+8k+VySGf//tn38VpJvJPlWkj8Z3Ha2Ng089qVJNgAbZtj3VO/qpCSb29/sVQPrZ/ob3y/Jua3ua5K8eGD7PZOc3mq5EnjMDG150MD86Un+cGD+2CSXtX8L1yY5JsnJwJOAd7Z/t++c6XXSLKrK2yK7AdcDT5u27FeBz8+0DfBF4Jfb9D7A49v0SqCAZQOP+zXgGuDwtu3HgQ+2dQ8BbgV+GtgdeCvwg4HneWObP47uDcmewKOBx9P1WlcCVwGvGHi+As4F7gM8FPg+sK49/32BK4HVc3ydfqR9rY7vAT/f5o9rbf3JVt/rgC+0dU8GNgJp8/sBtwH3m+H1fQXwj8AhwL2A9wJnDLyef92mfxG4FjhzYN05bfrNwHuA3drtSVPPPUO7CvgssD9wf+CfgBftqE0Djz2/PXbP7bxmZwB7A/8F2LaDv/GFwLuAPegCdxtwdNv+FOBz7fkOBS4HNk2r50ED86cDf9imHwv8K/D09lwHAw9u6y6YarO3u/n/YtIFeBvBH7U7IN0K3DRw+x6zh8JFwJuAA6btZ+oAMBgK64CXDMwf2Q4Cy4DXTx3s2rq9gNunHTAu2kHtrwA+MTBfwBMH5i8BXj0w/6fAO+b4Ok217ya6A3rRBdnUgf5vgRMHtt+lvY4PAALcADy5rXsx8JlZXt+rpg6CbX7FwGv2wPb8u9Ad9H996qAIrAVe2ab/ADhn8AC5nXYVcMzA/EuAdTtq08BjnzrEa/bggWV/DLx/pr8x3YH+TuDeA8veDJzepr8xrdaTGD4U3gu8fZY6L8BQmNPN4aPF67iq2nfqRndgmM2JwE8AX0/y5STP3s629wO+OTD/TbqD20Ft3capFVX1PeDb0x6/cXAmyU+0YZF/acMNfwQcMO0xNw5M3zbD/D4zFZruE0BTJ5GftJ02HdD28TvAU+jeiUN38D+1DdncBHyHLgwOru7I8xHg+W3bXwQ+PMv+HwB8YmA/V9EdKA+qqmvpAvyRdO/+zwM2JzkS+Bm6d9kAf0L3Dv/TbVhoRyfEB1/nb9L9bbbbplkee3f3P33d/YDvVNUt07Y/eGD99H0N61C6npV2IkNBVNWGqno+cCDwFuDsJHvTvUubbjPdgWXK/YE76A7UW+iGSIBuvBj4selPN23+3cDXgSOq6j7Aa+kOUvdYdZ8A2qfdPreDbe+sqj8F/p27AnQj8OuD4VpVe1bVF9r6M4DntTH5xwEfm2X3G4FnTNvPHlX1z239hcDzgN3bsguBX6Ebkrqs1XdLVb2qqg4HngO8MsnR22nSoQPT96f7uw3TJpj57z7s/qc/fjOwf5J7T9t+qu1bZtjXoO/R9Tin/PjA9Ea6ntZMvPzzHBkKIskLkiyvqh/SDWVA9052G/BDuvH7KWcAv53ksCT70L2zP7O6T5icDTwnyU+1k79vYscH+HsDNwO3Jnkw8D93Vrvm6BTgd5PsQTec85okDwVIct8kx09tWFWX0r1G7wM+VVU3zbLP9wAnD5ykXp7k2IH1FwK/yV0n9i8AXkY33Hdne8yz24nn0L1ed7bbbP5Xkv2SHAq8HDhzoJZZ23Q3/H6Svdp+Xjiw/x9RVRuBLwBvTrJHkofT9UynelVntXr2S3JIa/egy4BfTLJrkmPoek9T3g+8MMnR6U7mH9z+DUH3JuVwdLcZCgI4Brgiya3AqcAJVfXvbfjnZOAf2nDD44EPAB+kO4BdR/fO+mUAVXVFm/4I3TvAW4CtdCeHZ/M7dEMvtwB/ziwHlzH6G+C7wIur6hN0PaePtKGty4FnTNv+DOBpwF9tZ5+n0p0s/3SSW+hOOj9uYP2FdOE4FQqfp3t3fNHANkcAf0831PRF4F21/e9BnEN3/uWy1qb3AwzZpmFcSDectQ54a1V9ejvbPp/uXMRm4BPAG+quj/y+iW7I6Drg03T/tga9nK5ndBPwS8Anp1ZU1cV0gfR2uhPOF3JXL/ZUul7cd5P82Rzat2RNnVCTdrrWk7iJbmjougmXs2QkKbrX/JoR7Hsl3QF8t/L7B4uSPQXtVEme04YV9qb7JM/X6D6JI2kBMBS0sx1LN0ywmW7I44SyOyotGA4fSZJ69hQkSb0FfUG8Aw44oFauXDnpMiRpQbnkkku+VVXLZ1q3oENh5cqVrF+/ftJlSNKCkmTWb447fCRJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6i3obzTfUyvX/M3In+P6U5418ueQpJ3FnoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6hoIkqWcoSJJ6IwuFJB9IsjXJ5QPL9k9yfpIN7X6/gXWvSXJNkquT/Nyo6pIkzW6UPYXTgWOmLVsDrKuqI4B1bZ4kDwFOAB7aHvOuJLuOsDZJ0gxGFgpVdRHwnWmLjwXWtum1wHEDyz9SVd+vquuAa4DHjqo2SdLMxn1O4aCq2gLQ7g9syw8GNg5st6ktkySN0Xw50ZwZltWMGyYnJVmfZP22bdtGXJYkLS3jDoUbk6wAaPdb2/JNwKED2x0CbJ5pB1V1WlWtqqpVy5cvH2mxkrTUjDsUzgVWt+nVwDkDy09Icq8khwFHABePuTZJWvKWjWrHSc4AngIckGQT8AbgFOCsJCcCNwDHA1TVFUnOAq4E7gBeWlV3jqo2SdLMRhYKVfX8WVYdPcv2JwMnj6oeSdKOzZcTzZKkecBQkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUm8ioZDkt5NckeTyJGck2SPJ/knOT7Kh3e83idokaSkbeygkORj4LWBVVT0M2BU4AVgDrKuqI4B1bV6SNEaTGj5aBuyZZBmwF7AZOBZY29avBY6bTGmStHSNPRSq6p+BtwI3AFuAf62qTwMHVdWWts0W4MCZHp/kpCTrk6zftm3buMqWpCVhEsNH+9H1Cg4D7gfsneQFwz6+qk6rqlVVtWr58uWjKlOSlqRJDB89DbiuqrZV1Q+AjwM/BdyYZAVAu986gdokaUmbRCjcADw+yV5JAhwNXAWcC6xu26wGzplAbZK0pC0b9xNW1ZeSnA18BbgDuBQ4DdgHOCvJiXTBcfy4a5OkpW7soQBQVW8A3jBt8ffpeg2SpAnxG82SpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpN5QoZDkYaMuRJI0ecP2FN6T5OIkL0my7ygLkiRNzlChUFU/DfwScCiwPslfJXn6SCuTJI3d0OcUqmoD8Drg1cDPAH+W5OtJ/tuoipMkjdew5xQenuTtdL+l/FTgOVX1k2367SOsT5I0RsP+HOc7gT8HXltVt00trKrNSV43ksokSWM3bCg8E7itqu4ESLILsEdVfa+qPjiy6iRJYzXsOYW/B/YcmN+rLZMkLSLDhsIeVXXr1Eyb3ms0JUmSJmXYUPi3JEdNzSR5NHDbdraXJC1Aw55TeAXw0SSb2/wK4BdGUpEkaWKGCoWq+nKSBwNHAgG+XlU/GGllkqSxG7anAPAYYGV7zKOSUFV/OZKqJEkTMVQoJPkg8EDgMuDOtrgAQ0GSFpFhewqrgIdUVY2yGEnSZA376aPLgR8fZSGSpMkbtqdwAHBlkouB708trKrnzuVJ2+W33wc8jG4Y6teAq4Ez6c5bXA/8j6r67lz2L0mam2FD4Y07+XlPBf6uqp6XZHe6L8K9FlhXVackWQOsobsiqyRpTIb9PYUL6d6979amvwx8ZS5PmOQ+wJOB97d9315VNwHHAmvbZmuB4+ayf0nS3A176ewXA2cD722LDgY+OcfnPBzYBvxFkkuTvC/J3sBBVbUFoN0fOEstJyVZn2T9tm3b5liCJGkmw55ofinwROBm6H9wZ8aD9hCWAUcB766qRwH/RjdUNJSqOq2qVlXVquXLl8+xBEnSTIYNhe9X1e1TM0mW0Z0gnotNwKaq+lKbP5suJG5MsqLtfwWwdY77lyTN0bChcGGS1wJ7tt9m/ijw13N5wqr6F2BjkiPboqOBK4FzgdVt2WrgnLnsX5I0d8N++mgNcCLwNeDXgf9H95HSuXoZ8OH2yaNvAC+kC6izkpwI3AAcfw/2L0mag2EviPdDup/j/POd8aRVdRndt6SnO3pn7F+SNDfDXvvoOmY4h1BVh+/0iiRJE3N3rn00ZQ+6oZ39d345kqRJGvbLa98euP1zVb0DeOpoS5Mkjduww0dHDczuQtdzuPdIKpIkTcyww0d/OjB9B+2CdTu9GknSRA376aOfHXUhkqTJG3b46JXbW19Vb9s55UiSJunufProMXTfOgZ4DnARsHEURUmSJuPu/MjOUVV1C0CSNwIfraoXjaowSdL4DXvto/sDtw/M3073C2mSpEVk2J7CB4GLk3yC7pvNPw/85ciqkiRNxLCfPjo5yd8CT2qLXlhVl46uLEnSJAw7fATd7yjfXFWnApuSHDaimiRJEzLsz3G+AXg18Jq2aDfgQ6MqSpI0GcP2FH4eeC7dT2dSVZvxMheStOgMGwq3V1XRLp+dZO/RlSRJmpRhQ+GsJO8F9k3yYuDv2Uk/uCNJmj92+OmjJAHOBB4M3AwcCby+qs4fcW2SpDHbYShUVSX5ZFU9GjAIJGkRG3b46B+TPGaklUiSJm7YbzT/LPAbSa6n+wRS6DoRDx9VYZKk8dtuKCS5f1XdADxjTPVIkiZoRz2FT9JdHfWbST5WVf99DDVJkiZkR+cUMjB9+CgLkSRN3o5CoWaZliQtQjsaPnpEkpvpegx7tmm460TzfUZanSRprLYbClW167gKkSRN3t25dLYkaZGbWCgk2TXJpUnOa/P7Jzk/yYZ2v9+kapOkpWqSPYWXA1cNzK8B1lXVEcC6Ni9JGqOJhEKSQ4BnAe8bWHwssLZNrwWOG3NZkrTkTaqn8A7gd4EfDiw7qKq2ALT7A2d6YJKTkqxPsn7btm0jL1SSlpKxh0KSZwNbq+qSuTy+qk6rqlVVtWr58uU7uTpJWtqGvSDezvRE4LlJngnsAdwnyYeAG5OsqKotSVYAWydQmyQtaWPvKVTVa6rqkKpaCZwAfKaqXgCcC6xum60Gzhl3bZK01M2n7ymcAjw9yQbg6W1ekjRGkxg+6lXVBcAFbfrbwNGTrEeSlrr51FOQJE2YoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqSeoSBJ6hkKkqTe2EMhyaFJPpvkqiRXJHl5W75/kvOTbGj3+427Nkla6ibRU7gDeFVV/STweOClSR4CrAHWVdURwLo2L0kao7GHQlVtqaqvtOlbgKuAg4FjgbVts7XAceOuTZKWuomeU0iyEngU8CXgoKraAl1wAAfO8piTkqxPsn7btm1jq1WSloKJhUKSfYCPAa+oqpuHfVxVnVZVq6pq1fLly0dXoCQtQRMJhSS70QXCh6vq423xjUlWtPUrgK2TqE2SlrJJfPoowPuBq6rqbQOrzgVWt+nVwDnjrk2SlrplE3jOJwK/DHwtyWVt2WuBU4CzkpwI3AAcP4HaJGlJG3soVNXngcyy+uhx1iJJ+lF+o1mS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1DMUJEk9Q0GS1Bv7bzQvNSvX/M3In+P6U5418ueA8bRlHMb1ekkLkT0FSVLPUJAk9Rw+WgQWy7COpMmzpyBJ6hkKkqSeoSBJ6nlOQRqRxfJx5HGds/KjwvODPQVJUs+egrSA+cmz+Wkh9xLnXU8hyTFJrk5yTZI1k65HkpaSedVTSLIr8H+BpwObgC8nObeqrpxsZVpMfHctzW6+9RQeC1xTVd+oqtuBjwDHTrgmSVoy5lVPATgY2Dgwvwl43OAGSU4CTmqztya5+h483wHAt+7B4+eLxdIOsC3z0VjakbeM+hmAxfM3IW+5R215wGwr5lsoZIZl9SMzVacBp+2UJ0vWV9WqnbGvSVos7QDbMh8tlnaAbRnGfBs+2gQcOjB/CLB5QrVI0pIz30Lhy8ARSQ5LsjtwAnDuhGuSpCVjXg0fVdUdSX4T+BSwK/CBqrpihE+5U4ah5oHF0g6wLfPRYmkH2JYdSlXteCtJ0pIw34aPJEkTZChIknpLMhQW2qU0knwgydYklw8s2z/J+Uk2tPv9Bta9prXt6iQ/N5mq/7Mkhyb5bJKrklyR5OVt+UJsyx5JLk7y1daWN7XlC64t0F1NIMmlSc5r8wu1Hdcn+VqSy5Ksb8sWalv2TXJ2kq+3/zNPGEtbqmpJ3ehOYF8LHA7sDnwVeMik69pBzU8GjgIuH1j2x8CaNr0GeEubfkhr072Aw1pbd510G1ptK4Cj2vS9gX9q9S7EtgTYp03vBnwJePxCbEur75XAXwHnLdR/X62+64EDpi1bqG1ZC7yoTe8O7DuOtizFnsKCu5RGVV0EfGfa4mPp/tHQ7o8bWP6Rqvp+VV0HXEPX5omrqi1V9ZU2fQtwFd232BdiW6qqbm2zu7VbsQDbkuQQ4FnA+wYWL7h2bMeCa0uS+9C9GXw/QFXdXlU3MYa2LMVQmOlSGgdPqJZ74qCq2gLdwRY4sC1fEO1LshJ4FN077AXZljbkchmwFTi/qhZqW94B/C7ww4FlC7Ed0AXzp5Nc0i6JAwuzLYcD24C/aMN670uyN2Noy1IMhR1eSmOBm/ftS7IP8DHgFVV18/Y2nWHZvGlLVd1ZVY+k++b9Y5M8bDubz8u2JHk2sLWqLhn2ITMsm3g7Bjyxqo4CngG8NMmTt7PtfG7LMroh43dX1aOAf6MbLprNTmvLUgyFxXIpjRuTrABo91vb8nndviS70QXCh6vq423xgmzLlNatvwA4hoXXlicCz01yPd1Q6lOTfIiF1w4Aqmpzu98KfIJuCGUhtmUTsKn1PgHOpguJkbdlKYbCYrmUxrnA6ja9GjhnYPkJSe6V5DDgCODiCdT3nyQJ3RjpVVX1toFVC7Ety5Ps26b3BJ4GfJ0F1paqek1VHVJVK+n+L3ymql7AAmsHQJK9k9x7ahr4r8DlLMC2VNW/ABuTHNkWHQ1cyTjaMukz7JO4Ac+k++TLtcDvTbqeIeo9A9gC/IDuHcGJwI8B64AN7X7/ge1/r7XtauAZk65/oK6fpuvS/n/gsnZ75gJty8OBS1tbLgde35YvuLYM1PcU7vr00YJrB904/Ffb7Yqp/9sLsS2ttkcC69u/sU8C+42jLV7mQpLUW4rDR5KkWRgKkqSeoSBJ6hkKkqSeoSBJ6hkKUpPkznZ1zcuT/PXU9xDmsJ8/SPK0nVyeNBZ+JFVqktxaVfu06bXAP1XVyRMuSxorewrSzL5Iu6BYkgcm+bt2kbXPJXlwkvu2a/fv0rbZK8nGJLslOT3J89ryRye5sD32U0lWJDkwySVt/SOSVJL7t/lr276Obz2Wrya5aEKvgZYgQ0GaJsmudJcVmLr8yWnAy6rq0cDvAO+qqn+l++bsz7RtngN8qqp+MLCf3YD/AzyvPfYDwMnVXZdnj3Z55CfRfWv1SUkeQHdxuu8Brwd+rqoeATx3tC2W7rJs0gVI88ie7VLYK4FLgPPbFV1/Cvhod+kmoPshE4AzgV8APkt33aB3TdvfkcDD2n6g+4GnLW3dF+guRvdk4I/oLqYX4HNt/T8Apyc5C/g40pgYCtJdbquqRya5L3Ae8FLgdOCm6i6RPd25wJuT7A88GvjMtPUBrqiqJ8zw2M/R9RIeQHdRs1fTXRfqPICq+o0kj6P78ZvLkjyyqr59D9sn7ZDDR9I0bWjot+iGim4DrktyPHRXek3yiLbdrXRXojyV7kJyd07b1dXA8iRPaI/dLclD27qLgBcAG6rqh3S/rPdMuh4CSR5YVV+qqtcD3+JHL4ssjYyhIM2gqi6lO2dwAvBLwIlJpq6+OfjzrWfSHdzPnGEftwPPA97SHnsZ3VAUVXV922zqJPLn6Xok323zf5LuB+gvb9t8dac1TtoOP5IqSerZU5Ak9QwFSVLPUJAk9QwFSVLPUJAk9QwFSVLPUJAk9f4DSOJzMI/ZSgwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scrape_time</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>147</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>00:14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>01:00</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td></td>\n",
       "      <td>60.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td></td>\n",
       "      <td>117.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Scrape_time Reviews\n",
       "count          147        \n",
       "min          00:14     0.0\n",
       "max          01:00   569.0\n",
       "median                 4.0\n",
       "mean                  60.1\n",
       "std                  117.9"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the frequency distrubution of reviews per product\n",
    "plt.hist(download_stats_df['Reviews'], range = (0,600), bins = 12)\n",
    "plt.title('Histogram - Reviews per product')\n",
    "plt.xlabel('Reviews')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "download_stats_df.agg({\"Scrape_time\": [\"count\", \"min\", \"max\"],\n",
    "                       \"Reviews\": [\"min\", \"max\", \"median\", \"mean\", \"std\"]}).round(1).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf5306-a856-46e9-83d9-81abc44a1777",
   "metadata": {},
   "source": [
    "# Combine the files to produce a single master dataframe\n",
    "\n",
    "- The Key_specs_combined_df will be merged with the original_df based on 'ID'.\n",
    "- The combined dataframe will be known as the 'master_df' which will be saved to disk for later processing.\n",
    "- The master_df will not be visualised until **AFTER** it has been split into **Training and Testing sets** - to minimise and prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b783cf53-ce66-4d82-a8db-e42f4c0a0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: TV_names_and_links_df.pkl\n",
      "\n",
      "Dataframe has been saved to : //Product/Master_df.pkl\n"
     ]
    }
   ],
   "source": [
    "key_specs_combined_df = None\n",
    "current_directory = Path(\".\") #Get current directory\n",
    "folder1 = 'Reviews'\n",
    "folder2 = 'Key_specs'\n",
    "\n",
    "# Identify the number of products\n",
    "product_df = load_DataFrame('Product', f'TV_names_and_links_df.pkl')\n",
    "n = len(product_df['Product_Link'])\n",
    "\n",
    "merged_dataframes = {}\n",
    "\n",
    "for i in range(0, n):\n",
    "    file1 = f'Reviews_{i}.pkl'\n",
    "    file2 = f'KeySpecs_{i}.pkl'\n",
    "    \n",
    "    # Load the review file\n",
    "    Rev = load_DataFrame(folder1, file1, print_msg = False)\n",
    "    \n",
    "    # Reset the index of the dataframe. The review number captures the original index anyway (Review_num).\n",
    "    Rev.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Identify the columns in the Review file (dataframe)\n",
    "    Rev_columns = Rev.columns.to_list()\n",
    "\n",
    "    # Identify the number of reviews in the Review file\n",
    "    Rev_count = len(Rev.index)\n",
    "    \n",
    "    if Rev_count > 0:\n",
    "        # Count the stars per review\n",
    "        Rev_1_star = len(Rev[Rev['Review_star_count'] == 1])\n",
    "        Rev_2_star = len(Rev[Rev['Review_star_count'] == 2])\n",
    "        Rev_3_star = len(Rev[Rev['Review_star_count'] == 3])\n",
    "        Rev_4_star = len(Rev[Rev['Review_star_count'] == 4])\n",
    "        Rev_5_star = len(Rev[Rev['Review_star_count'] == 5])\n",
    "        Rev_avg_star = ((1 * Rev_1_star) + (2 * Rev_2_star) + (3 * Rev_3_star) + (4 * Rev_4_star) + (5 * Rev_5_star)) / Rev_count\n",
    "    else:\n",
    "        Rev_1_star = np.nan\n",
    "        Rev_2_star = np.nan\n",
    "        Rev_3_star = np.nan\n",
    "        Rev_4_star = np.nan\n",
    "        Rev_5_star = np.nan\n",
    "        Rev_avg_star = np.nan\n",
    "\n",
    "    # Flatten the Reviews to a single row (separated by a pipe '|')\n",
    "    Rev_flat_dict = {}\n",
    "    for col in Rev_columns:\n",
    "        if col == \"ID\":\n",
    "            Rev_flat_dict['ID'] = Rev['ID'][0]\n",
    "            Rev_flat_dict['Review_flat_count'] = Rev_count\n",
    "            Rev_flat_dict['Review_flat_1_star'] = Rev_1_star\n",
    "            Rev_flat_dict['Review_flat_2_star'] = Rev_2_star\n",
    "            Rev_flat_dict['Review_flat_3_star'] = Rev_3_star\n",
    "            Rev_flat_dict['Review_flat_4_star'] = Rev_4_star\n",
    "            Rev_flat_dict['Review_flat_5_star'] = Rev_5_star\n",
    "            Rev_flat_dict['Review_flat_avg_star'] = round(Rev_avg_star, 2)\n",
    "        else:\n",
    "            Rev_flat_dict[col] = '<|>'.join([str(elem) for elem in Rev[col].tolist()]) \n",
    "\n",
    "    # Convert back to dataframe        \n",
    "    Rev_flat_df = pd.DataFrame(Rev_flat_dict, index=[0])\n",
    "\n",
    "    \n",
    "    # Load the Key Specs file\n",
    "    K_specs= load_DataFrame(folder2, file2, print_msg = False)\n",
    "\n",
    "    # Merge the two dataframes by ID only if the product has reviews.\n",
    "    if len(Rev_flat_df.columns) > 0 :\n",
    "        merged_df = pd.merge(K_specs, Rev_flat_df, on='ID', how='outer') # Use ID as the common column\n",
    "    else:\n",
    "        merged_df = K_specs\n",
    "    \n",
    "    # Add this dataframe to the list\n",
    "    merged_dataframes[i] = merged_df\n",
    "\n",
    "\n",
    "# Combine all the rows to a single dataframe. Note that the columns for each dataframe may be slightly different depending on specifications mentioned\n",
    "frames = list(merged_dataframes.values())\n",
    "Key_specs_combined_df = pd.concat(frames)\n",
    "\n",
    "# Load the original products dataframe\n",
    "product_df = load_DataFrame('Product', 'TV_names_and_links_df.pkl', print_msg=False)\n",
    "\n",
    "# Combine the original dataframe to the Key_specs_combined_df\n",
    "master_df = pd.merge(product_df, Key_specs_combined_df, on=\"ID\", how='outer')\n",
    "\n",
    "# Save the master_df as a pickle file \n",
    "save_DataFrame(master_df, 'Product', 'Master_df.pkl', print_msg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8097e72-d0f1-4608-af7e-ea41e404583e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1301aeb-7173-43e2-b883-21bd7b8208f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
